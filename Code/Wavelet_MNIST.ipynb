{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_wavelets as pw\n",
    "from torch.nn.modules.utils import _pair, _quadruple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "#from online: the mean of MNIST is 0.1307, the std 0.3081\n",
    "# https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root= '../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "#keep batches in 4\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WavePool2d(nn.Module):\n",
    "    \"\"\" Pool with approximation coefficients of 2d Wavelet transform (stride = 1)module.\n",
    "    \n",
    "    Args:\n",
    "         kernel_size: size of pooling kernel, int or 2-tuple\n",
    "         stride: pool stride, int or 2-tuple\n",
    "         padding: pool padding, int or 4-tuple (l, r, t, b) as in pytorch F.pad\n",
    "         same: override padding and enforce same padding, boolean\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=3, stride=1, padding=0, same=False):\n",
    "        super(WavePool2d, self).__init__()\n",
    "        self.k = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _quadruple(padding)  # convert to l, r, t, b\n",
    "        self.same = same\n",
    "\n",
    "    def _padding(self, x):\n",
    "        if self.same:\n",
    "            ih, iw = x.size()[2:]\n",
    "            if ih % self.stride[0] == 0:\n",
    "                ph = max(self.k[0] - self.stride[0], 0)\n",
    "            else:\n",
    "                ph = max(self.k[0] - (ih % self.stride[0]), 0)\n",
    "            if iw % self.stride[1] == 0:\n",
    "                pw = max(self.k[1] - self.stride[1], 0)\n",
    "            else:\n",
    "                pw = max(self.k[1] - (iw % self.stride[1]), 0)\n",
    "            pl = pw // 2\n",
    "            pr = pw - pl\n",
    "            pt = ph // 2\n",
    "            pb = ph - pt\n",
    "            padding = (pl, pr, pt, pb)\n",
    "        else:\n",
    "            padding = self.padding\n",
    "        return padding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, self._padding(x))\n",
    "        x = x.unfold(2, self.k[0], self.stride[0]).unfold(3, self.k[1], self.stride[1])\n",
    "        xfm = pw.DWTForward(J = 2, wave = 'haar', mode = 'zero')\n",
    "        y = torch.zeros(22,22,1,1)\n",
    "        for i in range(x.size(0)):\n",
    "            for j in range(x.size(1)):\n",
    "                y = torch.cat((y,xfm(x[i][j])[0]), 3)\n",
    "        y = y[:,:,:,1:]\n",
    "\n",
    "        y = y.reshape(4,64, 22, 22)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(30976, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.pool = WavePool2d()\n",
    "        #haar wavelet transform, zero padding\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "train_loss = []\n",
    "run_loss = []\n",
    "test_loss = []\n",
    "test_accuracy = []\n",
    "\n",
    "#loss function: Log Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#stochastic gradient descent\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "for epoch in range(5):  # loop/over the dataset multiple times\n",
    "    training_loss = 0\n",
    "    running_loss = 0.0\n",
    "    num_images = 0\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        num_images += inputs.size(1)\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        training_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] running loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / num_images))\n",
    "            run_loss.append(running_loss / num_images)\n",
    "            running_loss = 0.0\n",
    "    train_loss.append(training_loss / num_images)\n",
    "\n",
    "    testing_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            output = net(data)\n",
    "            testing_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    \n",
    "    test_loss.append(testing_loss / len(testloader.dataset))\n",
    "    test_accuracy.append(correct/ len(testloader.dataset))\n",
    "    \n",
    "    print('Epoch %d, Training Loss:  %.3f, Testing Loss: %.3f, Testing Accuracy: %.3f' %\n",
    "         (epoch + 1, training_loss / num_images, testing_loss / len(testloader.dataset), correct/ len(testloader.dataset))) \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
